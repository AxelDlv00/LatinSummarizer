{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Fine-Tuning mT5 for Latin Translation & Summarization**\n",
    "\n",
    "This notebook contains two main parts:\n",
    "\n",
    "1. **Training mT5** for **English → Latin translation** and **summary extraction**.\n",
    "2. **Fine-Tuning mT5** for **Latin → Latin summarization**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Table of Contents**\n",
    "\n",
    "### 1. Training mT5 for English → Latin Translation & Summarization\n",
    "- 1.1 **Load Libraries**\n",
    "- 1.2 **Define Global Parameters**\n",
    "- 1.3 **Load Dataset**\n",
    "- 1.4 **Initialize Model & Tokenizer**\n",
    "- 1.5 **Training Process**\n",
    "- 1.6 **Evaluate BLEU & CHRF Score**\n",
    "\n",
    "### 2. Fine-Tuning mT5 for Latin → Latin Summarization\n",
    "- 2.1 **Load Libraries**\n",
    "- 2.2 **Define Global Parameters**\n",
    "- 2.3 **Load Dataset**\n",
    "- 2.4 **Initialize Model & Tokenizer**\n",
    "- 2.5 **Fine-Tuning Process**\n",
    "- 2.6 **Evaluate ROUGE & BERTScore**\n",
    "- 2.7 **Grade Summaries with Mistral Model**\n",
    "- 2.8 **Save Final Model & Results**\n",
    "\n",
    "---\n",
    "\n",
    "## **Workflow Overview**\n",
    "This notebook fine-tunes **mT5**, a multilingual sequence-to-sequence transformer, for two tasks:\n",
    "1. **English to Latin translation and summarization**: Training on a parallel corpus with structured prompts.\n",
    "2. **Latin to Latin summarization**: Using extractive summaries for fine-tuning and evaluation.\n",
    "\n",
    "The process includes:\n",
    "- **Dataset preparation**: Tokenization, prompt generation, and pretraining corpus setup.\n",
    "- **Model fine-tuning**: Training mT5 with **LoRA adapters** for efficient tuning.\n",
    "- **Evaluation metrics**: Computing **BLEU, CHRF, ROUGE, and BERTScore** to measure translation and summarization performance.\n",
    "- **Summary grading**: Using a **Mistral model** to assess the quality of generated summaries.\n",
    "- **Final model export**: Saving the trained model for deployment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training mT5 for English → Latin Translation & Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "from transformers import AdamW, AutoModelForSeq2SeqLM, AutoTokenizer, get_linear_schedule_with_warmup\n",
    "from utils.mT5_train import training_loop, plot_training\n",
    "from utils.bleu import calculate_bleu_and_chrf\n",
    "from peft import get_peft_model, LoraConfig\n",
    "from utils.generate_translation import generate_translation, generate_translation_with_options, inference_from_csv, inference_from_csv_adding_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"Global-Parameters\"></a> Define Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aiming to train a model to translate and summarize la texts using en as a pivot.\n",
      "Training data: /Data/AxelDlv/LatinSummarizer/prompt_with_stanza_train.csv | Testing data: /Data/AxelDlv/LatinSummarizer/prompt_with_stanza_test.csv\n",
      "Training for 5 epochs with batch size 4 and learning rate 0.0005.\n"
     ]
    }
   ],
   "source": [
    "# Global parameters for translation training\n",
    "language1 = \"en\"\n",
    "language2 = \"la\"\n",
    "path_to_train = \"/Data/AxelDlv/LatinSummarizer/prompt_with_stanza_train.csv\"\n",
    "path_to_test = \"/Data/AxelDlv/LatinSummarizer/prompt_with_stanza_test.csv\"\n",
    "path_to_special_tokens = \"/Data/AxelDlv/LatinSummarizer/stanza_merged_tags_la_en.csv\"\n",
    "\n",
    "max_seq_len = 512\n",
    "max_new_tokens = 512\n",
    "model_pretrained = \"mt5-small\"\n",
    "model_name = f\"/Data/AxelDlv/mt5-small-en-la-translation/{model_pretrained}\"  # Adjust as needed\n",
    "preexisting_checkpoint_path = \"\"  # Leave empty if not using a previous checkpoint\n",
    "checkpoint_dir = f\"/Data/AxelDlv/mt5-small-en-la-translation\"\n",
    "checkpoint_prefix = \"mt5-small-en-la-translation-final_with_stanza\"\n",
    "\n",
    "batch_size = 4\n",
    "lr = 5e-4\n",
    "start_epoch = 0\n",
    "end_epoch = 5\n",
    "\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(f\"Aiming to train a model to translate and summarize {language2} texts using {language1} as a pivot.\")\n",
    "print(f\"Training data: {path_to_train} | Testing data: {path_to_test}\")\n",
    "print(f\"Training for {end_epoch} epochs with batch size {batch_size} and learning rate {lr}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"Load-Dataset\"></a> Load Dataset\n",
    "\n",
    "We assume that the dataset has been pre-processed in two csv files with columns 'prompt', 'answer', 'prefix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "      <th>prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;la&gt; &lt;no_stanza&gt; rogabis eum et exaudiet te et...</td>\n",
       "      <td>Thou shalt pray to him, and he will hear thee,...</td>\n",
       "      <td>la.en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;en&gt; &lt;no_stanza&gt; Here I ask, if sufficient pro...</td>\n",
       "      <td>hic quaero, si Hiempsali satis est cautum  foe...</td>\n",
       "      <td>en.la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;en&gt; &lt;no_stanza&gt; Africans and warlike Spaniard...</td>\n",
       "      <td>ast hic, tranquillo qua labitur agmine flumen,...</td>\n",
       "      <td>en.la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;en&gt; &lt;no_stanza&gt; For who does not realize that...</td>\n",
       "      <td>Quis est enim qui hoc non intellegat, nisi Cae...</td>\n",
       "      <td>en.la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;la&gt; 9 Sed dicebat, quod aliquis dicitur vider...</td>\n",
       "      <td>9 Sed dicebat, quod aliquis dicitur videre non...</td>\n",
       "      <td>la.la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633514</th>\n",
       "      <td>&lt;la&gt; &lt;with_stanza&gt; Duo &lt;NUM&gt; tamen &lt;ADV&gt; agger...</td>\n",
       "      <td>However &lt;ADV&gt; , &lt;PUNCT&gt; two &lt;NUM&gt; lofty &lt;ADJ&gt; ...</td>\n",
       "      <td>la.en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633515</th>\n",
       "      <td>&lt;la&gt; O homo, audi et intellige verba illius qu...</td>\n",
       "      <td>O homo, audi et intellige verba illius qui era...</td>\n",
       "      <td>la.la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633516</th>\n",
       "      <td>&lt;en&gt; &lt;with_stanza&gt; And &lt;CCONJ&gt; he &lt;PRON&gt; shall...</td>\n",
       "      <td>et reget illas in virga ferrea tamquam vas fig...</td>\n",
       "      <td>en.la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633517</th>\n",
       "      <td>&lt;la&gt; ad 7 Ad septimum dicendum, quod duplicite...</td>\n",
       "      <td>ad 7 Ad septimum dicendum, quod dupliciter ali...</td>\n",
       "      <td>la.la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633518</th>\n",
       "      <td>&lt;la&gt; ad 14 Ad decimumquartum dicendum quod iud...</td>\n",
       "      <td>ad 14 Ad decimumquartum dicendum quod iudicium...</td>\n",
       "      <td>la.la</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>633519 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   prompt  \\\n",
       "0       <la> <no_stanza> rogabis eum et exaudiet te et...   \n",
       "1       <en> <no_stanza> Here I ask, if sufficient pro...   \n",
       "2       <en> <no_stanza> Africans and warlike Spaniard...   \n",
       "3       <en> <no_stanza> For who does not realize that...   \n",
       "4       <la> 9 Sed dicebat, quod aliquis dicitur vider...   \n",
       "...                                                   ...   \n",
       "633514  <la> <with_stanza> Duo <NUM> tamen <ADV> agger...   \n",
       "633515  <la> O homo, audi et intellige verba illius qu...   \n",
       "633516  <en> <with_stanza> And <CCONJ> he <PRON> shall...   \n",
       "633517  <la> ad 7 Ad septimum dicendum, quod duplicite...   \n",
       "633518  <la> ad 14 Ad decimumquartum dicendum quod iud...   \n",
       "\n",
       "                                                   answer prefix  \n",
       "0       Thou shalt pray to him, and he will hear thee,...  la.en  \n",
       "1       hic quaero, si Hiempsali satis est cautum  foe...  en.la  \n",
       "2       ast hic, tranquillo qua labitur agmine flumen,...  en.la  \n",
       "3       Quis est enim qui hoc non intellegat, nisi Cae...  en.la  \n",
       "4       9 Sed dicebat, quod aliquis dicitur videre non...  la.la  \n",
       "...                                                   ...    ...  \n",
       "633514  However <ADV> , <PUNCT> two <NUM> lofty <ADJ> ...  la.en  \n",
       "633515  O homo, audi et intellige verba illius qui era...  la.la  \n",
       "633516  et reget illas in virga ferrea tamquam vas fig...  en.la  \n",
       "633517  ad 7 Ad septimum dicendum, quod dupliciter ali...  la.la  \n",
       "633518  ad 14 Ad decimumquartum dicendum quod iudicium...  la.la  \n",
       "\n",
       "[633519 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    df_train = pd.read_csv(path_to_train)\n",
    "    df_test = pd.read_csv(path_to_test)\n",
    "except:\n",
    "    # Give an example of df_train and df_test\n",
    "    df_train = pd.DataFrame({\n",
    "        \"prefix\": [\"<en.la>\", \"<en.la>\"],\n",
    "        \"prompt\": [\"This is a sample text\", \"This is another sample text\"],\n",
    "        \"answer\": [\"Hic est exemplum\", \"Hic est aliud exemplum\"]\n",
    "    })\n",
    "    df_test = pd.DataFrame({\n",
    "        \"prefix\": [\"<en.la>\", \"<en.la>\"],\n",
    "        \"prompt\": [\"This is a sample text\", \"This is another sample text\"],\n",
    "        \"answer\": [\"Hic est exemplum\", \"Hic est aliud exemplum\"]\n",
    "    })\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "      <th>prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;la&gt; &lt;no_stanza&gt; Aperuerat iam Italiam bellumq...</td>\n",
       "      <td>The road into Italy had already been opened an...</td>\n",
       "      <td>la.en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;la&gt; &lt;no_stanza&gt; Usus practicus unus est ad al...</td>\n",
       "      <td>One practical use is for altitude of geopotent...</td>\n",
       "      <td>la.en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;la&gt; &lt;with_stanza&gt; praeferunt &lt;VERB&gt; gustandi ...</td>\n",
       "      <td>As if we were not far inferior in this even to...</td>\n",
       "      <td>la.en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;en&gt; &lt;no_stanza&gt; But let all things be done de...</td>\n",
       "      <td>omnia autem honeste et secundum ordinem fiant ...</td>\n",
       "      <td>en.la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;la&gt; Affert secundus ramus persicum, ex persic...</td>\n",
       "      <td>Affert secundus ramus persicum, ex persico, et...</td>\n",
       "      <td>la.la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33338</th>\n",
       "      <td>&lt;la&gt; &lt;no_stanza&gt; Sed vos religiosi, qui eam qu...</td>\n",
       "      <td>But it is you who are the really religious peo...</td>\n",
       "      <td>la.en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33339</th>\n",
       "      <td>&lt;la&gt; &lt;no_stanza&gt; ne forte decepti faciatis vob...</td>\n",
       "      <td>Lest ye corrupt yourselves, and make you a gra...</td>\n",
       "      <td>la.en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33340</th>\n",
       "      <td>&lt;en&gt; &lt;with_stanza&gt; And &lt;CCONJ&gt; thou &lt;PRON&gt; sha...</td>\n",
       "      <td>et diliges Dominum Deum tuum ex toto corde tuo...</td>\n",
       "      <td>en.la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33341</th>\n",
       "      <td>&lt;la&gt; Hanc fabulam ponit Lucanus: Fuit, inquit,...</td>\n",
       "      <td>Hanc fabulam ponit Lucanus: Fuit, inquit, in L...</td>\n",
       "      <td>la.la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33342</th>\n",
       "      <td>&lt;en&gt; &lt;no_stanza&gt; But thou shalt eat them befor...</td>\n",
       "      <td>Thraeicii quondam quam saeva licentia regis fe...</td>\n",
       "      <td>en.la</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33343 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  prompt  \\\n",
       "0      <la> <no_stanza> Aperuerat iam Italiam bellumq...   \n",
       "1      <la> <no_stanza> Usus practicus unus est ad al...   \n",
       "2      <la> <with_stanza> praeferunt <VERB> gustandi ...   \n",
       "3      <en> <no_stanza> But let all things be done de...   \n",
       "4      <la> Affert secundus ramus persicum, ex persic...   \n",
       "...                                                  ...   \n",
       "33338  <la> <no_stanza> Sed vos religiosi, qui eam qu...   \n",
       "33339  <la> <no_stanza> ne forte decepti faciatis vob...   \n",
       "33340  <en> <with_stanza> And <CCONJ> thou <PRON> sha...   \n",
       "33341  <la> Hanc fabulam ponit Lucanus: Fuit, inquit,...   \n",
       "33342  <en> <no_stanza> But thou shalt eat them befor...   \n",
       "\n",
       "                                                  answer prefix  \n",
       "0      The road into Italy had already been opened an...  la.en  \n",
       "1      One practical use is for altitude of geopotent...  la.en  \n",
       "2      As if we were not far inferior in this even to...  la.en  \n",
       "3      omnia autem honeste et secundum ordinem fiant ...  en.la  \n",
       "4      Affert secundus ramus persicum, ex persico, et...  la.la  \n",
       "...                                                  ...    ...  \n",
       "33338  But it is you who are the really religious peo...  la.en  \n",
       "33339  Lest ye corrupt yourselves, and make you a gra...  la.en  \n",
       "33340  et diliges Dominum Deum tuum ex toto corde tuo...  en.la  \n",
       "33341  Hanc fabulam ponit Lucanus: Fuit, inquit, in L...  la.la  \n",
       "33342  Thraeicii quondam quam saeva licentia regis fe...  en.la  \n",
       "\n",
       "[33343 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"Model-and-Tokenizer\"></a> Initialize Model & Tokenizer\n",
    "\n",
    "The special tokens should be stored in a csv file with a column `token`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA integration complete.\n",
      "Special tokens added: ['<en>', '<la>', '<en.la>', '<la.en>', '<la.la>', '<with_stanza>', '<no_stanza>', '<clue>', '<EMPTY>', '<PAD>', '<ROOT>', '<UNK>', 'ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X']\n",
      "Model parameters: 300,530,048\n",
      "Tokenizer vocab size: 250100, total tokens: 250121\n"
     ]
    }
   ],
   "source": [
    "# Load special tokens and initialize tokenizer\n",
    "special_tokens = pd.read_csv(path_to_special_tokens)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.add_special_tokens({'additional_special_tokens': special_tokens['token'].tolist()})\n",
    "\n",
    "# Load the model and adjust token embeddings\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).cuda()\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# for n, _ in model.named_modules():\n",
    "#     if \".q\" in n or \".v\" in n:\n",
    "#         print(n)\n",
    "\n",
    "# Load pre-existing checkpoint if provided\n",
    "if preexisting_checkpoint_path and os.path.exists(preexisting_checkpoint_path):\n",
    "    model.load_state_dict(torch.load(preexisting_checkpoint_path))\n",
    "    print(f\"Loaded checkpoint from: {preexisting_checkpoint_path}\")\n",
    "\n",
    "# Integrate LoRA using PEFT (adjust target modules as needed)\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_2_SEQ_LM\"\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "print(\"LoRA integration complete.\")\n",
    "\n",
    "print(f\"Special tokens added: {special_tokens['token'].tolist()}\")\n",
    "print(f\"Model parameters: {model.num_parameters():,}\")\n",
    "print(f\"Tokenizer vocab size: {tokenizer.vocab_size}, total tokens: {len(tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"Training-Translation\"></a> Training Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimizer and scheduler\n",
    "n_batches = int(np.ceil(len(df_train) / batch_size))\n",
    "total_steps = n_batches * (end_epoch - start_epoch + 1)\n",
    "n_warmup_steps = int(total_steps * 0.01)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=n_warmup_steps, num_training_steps=total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer length: 250121\n",
      "Model embedding size: 250121\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenizer length:\", len(tokenizer)) \n",
    "# Should be 250121\n",
    "\n",
    "vocab_size_in_model = model.get_input_embeddings().weight.shape[0]\n",
    "print(\"Model embedding size:\", vocab_size_in_model)\n",
    "# If this is 250100, you have a mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training loop\n",
    "losses = training_loop(\n",
    "    model, df_train, df_test, tokenizer, optimizer, scheduler,\n",
    "    start_epoch, end_epoch, batch_size,\n",
    "    checkpoint_dir, checkpoint_prefix,\n",
    "    print_freq=1, \n",
    "    max_seq_len=max_seq_len,\n",
    "    use_amp=False, \n",
    "    accumulation_steps=1,\n",
    "    column_prompt=\"prompt\", \n",
    "    column_target=\"answer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free GPU memory and plot training loss\n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "plot_training(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"Evaluate-BLEU\"></a> Evaluate BLEU Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the checkpoint path (make sure the filename pattern matches your saved checkpoint)\n",
    "checkpoint_to_use = os.path.join(checkpoint_dir, f\"{checkpoint_prefix}-epoch-{end_epoch}.pt\")\n",
    "\n",
    "# Load the base model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).cuda()\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Integrate LoRA using the same configuration used during training\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],  # adjust if necessary\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_2_SEQ_LM\"\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Load the LoRA-adapted checkpoint\n",
    "model.load_state_dict(torch.load(checkpoint_to_use + \".pt\"))\n",
    "model.eval()\n",
    "print(f'Model loaded from {checkpoint_to_use}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_score, chrf_score = calculate_bleu_and_chrf(\n",
    "    df_test, language1, language2, tokenizer, model,\n",
    "    max_examples_to_test=500,\n",
    "    column_prompt=\"prompt\", column_target=\"answer\", column_prefix=\"prefix\",\n",
    "    max_input_len=max_seq_len, max_output_len=max_new_tokens\n",
    ")\n",
    "print(f\"BLEU Score: {bleu_score}, CHRF Score: {chrf_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_score, chrf_score = calculate_bleu_and_chrf(df_test, language1, language2, tokenizer, model, max_examples_to_test=500, column_prompt=\"prompt\", column_target=\"answer\", column_prefix=\"prefix\", max_input_len=max_seq_len, max_output_len=max_new_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning SLM on 'la' -> 'la' summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "from transformers import AdamW, AutoModelForSeq2SeqLM, AutoTokenizer, get_linear_schedule_with_warmup\n",
    "from utils.mT5_train import training_loop, plot_training\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "from utils.prompt_generator import generate_prompt_summaries\n",
    "from utils.generate_translation import generate_translation, generate_translation_with_options, inference_from_csv, inference_from_csv_adding_column\n",
    "from utils.rouge import calculate_rouge_and_bertscore  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning mT5 for Latin summarization ('la' → 'la')\n",
      "Loading pre-trained model from /Data/AxelDlv/mt5-small-en-la-translation/mt5-small-en-la-translation-final_no_stanza-last_epoch\n",
      "Training for 100 epochs with batch size 8 and LR 1e-06\n"
     ]
    }
   ],
   "source": [
    "# Task description\n",
    "language = \"la\"  # Both input and output are in Latin\n",
    "\n",
    "# Paths to data\n",
    "path_to_train = \"/Data/AxelDlv/LatinSummarizer/train_translations.csv\"  # Latin summarization dataset\n",
    "path_to_test = \"/Data/AxelDlv/LatinSummarizer/val_translations.csv\"\n",
    "\n",
    "# Model and tokenizer\n",
    "max_seq_len = 412  # Maximum number of tokens of the input sequence\n",
    "max_new_tokens = 412  # Maximum number of tokens of the generated sequence\n",
    "model_pretrained = \"mt5-small\"\n",
    "model_name = f\"/Data/AxelDlv/{model_pretrained}\" \n",
    "# checkpoint_path = f\"/Data/AxelDlv/mt5-small-la-la-translation/mt5-small-la-la-translation-final-last_epoch\"\n",
    "checkpoint_path = f\"/Data/AxelDlv/mt5-small-en-la-translation/mt5-small-en-la-translation-final_no_stanza-last_epoch\"\n",
    "checkpoint_dir = f\"/Data/AxelDlv/mt5-small-la-la-translation\"  # Path to save the model\n",
    "checkpoint_prefix = \"mt5-small-la-la-translation-final\"  # Prefix of the model to save\n",
    "path_to_special_tokens = \"/Data/AxelDlv/LatinSummarizer/common_tags_la_en.csv\" \n",
    "\n",
    "# Training parameters\n",
    "start_epoch = 51  \n",
    "end_epoch = 100  # Fine-tuning needs fewer epochs\n",
    "batch_size = 8  \n",
    "lr = 1e-6  # Lower learning rate to preserve pre-trained weights\n",
    "\n",
    "# Print a summary\n",
    "print(f\"Fine-tuning mT5 for Latin summarization ('{language}' → '{language}')\")\n",
    "print(f\"Loading pre-trained model from {checkpoint_path}\")\n",
    "print(f\"Training for {end_epoch} epochs with batch size {batch_size} and LR {lr}\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "Assumes dataset has columns: 'prefix' (\"<la.la>\"), 'prompt' (full text), 'answer' (summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_train = pd.read_csv(path_to_train)\n",
    "    df_test = pd.read_csv(path_to_test)\n",
    "except:\n",
    "    df_train = pd.DataFrame({\n",
    "        \"prefix\": [\"<la.la>\", \"<la.la>\"],\n",
    "        \"prompt\": [\"Antiqua urbs Roma in historia notissima est.\", \n",
    "                   \"Imperium Romanum multas terras conquisivit.\"],\n",
    "        \"answer\": [\"Roma urbs antiqua notissima.\", \n",
    "                   \"Imperium Romanum multas terras cepit.\"]\n",
    "    })\n",
    "    df_test = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;la&gt; Ioannes Baptista Homann (natus die 20 Mar...</td>\n",
       "      <td>Ioannes Baptista Homann, natus die 1 mensis 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;la&gt; Schola iuris Berytensis fuit magnus locus...</td>\n",
       "      <td>Facultas iuris in Beryto, centrum antiquum Rom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;la&gt; Marsyas (Marsyas aut Marsya, ae, m. Graec...</td>\n",
       "      <td>Marsyas, etiam ut Oeagnum, Hyagnum, sive Olymp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;la&gt; Divitia, a decimo saeculo Tuitium (German...</td>\n",
       "      <td>Divitia, oppidum in regione Coloniae Agrippina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;la&gt; Paradisus in Eden (Hebraice גן בעדן \"gan ...</td>\n",
       "      <td>Erat autem ibi paradisus Eden, ubi Isaac hortu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745</th>\n",
       "      <td>&lt;la&gt; Cathopedia (Latine \"Cathopaedia\") est enc...</td>\n",
       "      <td>Cathopata, etiam vocabulo Cathopaedia, Catholi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746</th>\n",
       "      <td>&lt;la&gt; Genus activum accidit verbis Latinis. Sec...</td>\n",
       "      <td>Verbum \"puer\" est verbum Latinum quod possit u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4747</th>\n",
       "      <td>&lt;la&gt; The Song of Hiawatha ('Carmen Hiavathae')...</td>\n",
       "      <td>Song of Indonesia, written by Henry Wadsworth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4748</th>\n",
       "      <td>&lt;la&gt; Il nome della rosa (titulus Italicus, sci...</td>\n",
       "      <td>The text discusses the Italian mythology chara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4749</th>\n",
       "      <td>&lt;la&gt; Pamphilus Alexandrinus fuit grammaticus s...</td>\n",
       "      <td>Poeta Graeca Pamphilus, scribens in saeculo, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4750 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompt  \\\n",
       "0     <la> Ioannes Baptista Homann (natus die 20 Mar...   \n",
       "1     <la> Schola iuris Berytensis fuit magnus locus...   \n",
       "2     <la> Marsyas (Marsyas aut Marsya, ae, m. Graec...   \n",
       "3     <la> Divitia, a decimo saeculo Tuitium (German...   \n",
       "4     <la> Paradisus in Eden (Hebraice גן בעדן \"gan ...   \n",
       "...                                                 ...   \n",
       "4745  <la> Cathopedia (Latine \"Cathopaedia\") est enc...   \n",
       "4746  <la> Genus activum accidit verbis Latinis. Sec...   \n",
       "4747  <la> The Song of Hiawatha ('Carmen Hiavathae')...   \n",
       "4748  <la> Il nome della rosa (titulus Italicus, sci...   \n",
       "4749  <la> Pamphilus Alexandrinus fuit grammaticus s...   \n",
       "\n",
       "                                                 answer  \n",
       "0     Ioannes Baptista Homann, natus die 1 mensis 16...  \n",
       "1     Facultas iuris in Beryto, centrum antiquum Rom...  \n",
       "2     Marsyas, etiam ut Oeagnum, Hyagnum, sive Olymp...  \n",
       "3     Divitia, oppidum in regione Coloniae Agrippina...  \n",
       "4     Erat autem ibi paradisus Eden, ubi Isaac hortu...  \n",
       "...                                                 ...  \n",
       "4745  Cathopata, etiam vocabulo Cathopaedia, Catholi...  \n",
       "4746  Verbum \"puer\" est verbum Latinum quod possit u...  \n",
       "4747  Song of Indonesia, written by Henry Wadsworth ...  \n",
       "4748  The text discusses the Italian mythology chara...  \n",
       "4749  Poeta Graeca Pamphilus, scribens in saeculo, a...  \n",
       "\n",
       "[4750 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = generate_prompt_summaries(df_train, language, \"clean_text\", \"clean_text_summary_la\")\n",
    "df_test = generate_prompt_summaries(df_test, language, \"clean_text\", \"clean_text_summary_la\")\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt summary examples:\n",
      "Prompt: <la> Ioannes Baptista Homann (natus die 20 Martii 1664 Kammlach, mortuus die 1 Iulii 1724 Norimbergae) fuit geographus et cartographus Germanus, qui praecipue tabulas Americae fecit. Vita. Homann in Oberkammlach prope Kammlach in Electoratu Bavariae natus est. Quamquam in schola Iesuita educatus seque ad cursum ecclesiasticum parans, sua sententia de deis in Protestantismum commutata est, et post annum 1687 notarius iuris civilis Norimbergae in urbe libera imperiali laboravit. Mox in scalpturam et cartographiam animadvertit, annoque 1702 suam domum editorialem condidit. Homann clarus factus est cartographus Germanus princeps, qui anno 1715 ab imperatore Carolo VI creatus est Imperialis Geographus. (Hominibus talia privilegia concedere fuit ius Imperatoris Romani Sacri.) Eodem anno factus est sodalis Academiae Scientiarum Borussicae Berolini sitae. Momentum cartographiae proprium erant imperialia privilegia impressoria, quae ad tempus auctores protegebant in omnibus campis scientificis, inter quos impressores, scalptores in cupro, tabularum fabricatores, et qui libros edendos curaverunt. Haec privilegia momentum etiam habuerunt ut inlecebrae clientium emptorumque futurorum. Anno 1716, Homann \"Grosser Atlas ueber die ganze Welt\" (Grandis Omnium Orbis Terrarum Atlas), suum magnum opus, divulgavit, multas tabulas describens, scalptore Christophoro Weigel Seniore adiuvante, qui etiam \"Siebmachers Wappenbuch\" divulgaverit. Homann Norimbergae obiit. In eius locum successit et usque ad 1848 duravit eius heredum societas mercatoria, quae Homann Erben (Theodisce), Homanniani Heredes (Latine), et Heritiers de Homann (Francice) peregre appellabatur. <la> <la.la> <la>\n",
      "Summary: Ioannes Baptista Homann, natus die 1 mensis 1664 in Kammach, Bavaria, fuit geographer et cartographer Germanicus, qui cum consiliis ecclesiasticae ecclesiasticae, mox ad Protestantismum conversus est. Homannus, ut lex legum civilis noster Nobuberiensis meruit, ut sculptor, et aedificavit domum suam anno 1702 condidit. <la>\n",
      "\n",
      "Prompt: <la> Schola iuris Berytensis fuit magnus locus studiorum antiqui iuris Romani, Beryti sita, qui sub imperatorum Romanorum fide et clientela floruit. Scholae iuris per imperium conditae sunt ad constitutiones conservandas et studia iuris prudentiae promovenda, sic laboram allevantes imperialium tribunalium, cuius consulti facilius ad exempla priora spectarent. Origines scholae Berytensis sunt obscurae. Primum eius indicium scriptum A.D. 239 reperitur, ubi iam bona fama uti videtur. Schola cives Romanos iuvenes divitesque attraxit, et professores eius ad codicem Iustinianum scribendum adiuverunt. Propter vim famamque urbs Berytus mater vel nutrix legum appellata est. Cum Iustinianus I plures scholas iuris provinciales clauderet, Berytensem scholam paucasque alias perseverare sivit. Cursus studiorum quinque annos durabat, constans ex correctione et inspectione scriptorum iudicialium constitutionumque imperialium, ac disputatione singularum causarum. Iustinianus ipse particeps fuit administrationis, iubens tam praesidem Poeniciae maritimae quam Berytensem episcopum et legum professores ordinem rectamque disciplinam conservare. Aedificia scholae terrae motu anno 551 destructa sunt. Schola deinde Sidonem mota expugnationi Arabicae anni 635 superstes non fuit. Ex scriptis antiquis scimus scholam sitam fuisse iuxta ecclesiam Anastasis, cuius vestigia sub cathedrali Sancti Georgii in media urbe Beryto iacent. Bibliographia. < style=\"clear: ; text-align: left; box-sizing: border-box; width: ; margin: 1.5em auto; border-radius: 1em; box-shadow: 8px 8px 8px rgba(0, 0, 0, .2); \". 6. Translated by S. D. F. Salmond. Edinburgh: Christian Classics Etheral Library <la> <la.la> <la>\n",
      "Summary: Facultas iuris in Beryto, centrum antiquum Romanum doctrinarum iurisprudentiae, sub patronatione imperatorum Romanorum; leges auctoritatis constitutae erant necessariae ad stabilityem stabilitatemque iudiciorum studia firmandi; originis utriusque legum et doctrinae incertae sunt; primum legis indice legis in A.D. 239 scriptum est, et in Berytio primo est inventum fama bona. <la>\n",
      "\n",
      "Prompt: <la> Marsyas (Marsyas aut Marsya, ae, m. Graece : Μαρσύας), Oeagri (-us, i, m.Graece : Οἴαγρος) aut Hyagnis (-gnis, is, m. Graece : Ὑάγνις) aut Olympi (-us,i,m. Graece : Ὄλυμπος) filius (auctores enim de patre discrepant), in mythologia Graeca Phrygius satyrus fuit. Fabula. Phryx quidem egregie tibias inflabat, quarum nonnumquam inventor habetur, plerumque Minerva (Minerva, ae, f.). Dea autem aliquando prope fontem in Ida eas abiecerat quod buccae deformissime tumescerent dum inflat et imprecata est ut quisquis instrumentum sustulisset poenam impudentia dignam susciperet. Marsyas vero tibias forte inventas sustulit et cum primum eas miraretur ignorans quomodo uteretur se tam assidue exercebat ut in dies suaviores sonos faceret. Iam tamen palam gloriabatur se longe optimum musicum esse. Itaque Apollinem (Apollo, inis,m. Graece : Ἀπόλλων) provocavit qui certamen accepit dummodo victus victoris voluntati obsequeretur. Iudicibus autem Musis Midaque (Midas,ae, m. Graece : Μίδας) sumptis dubium erat uter melior musicus esset. Tandem Apollo lyram versavit et iterum modulatissime cecinit. Marsyas vero non potuit idem tibiis facere ut deus victor declararetur. Satyrum autem Apollo quippe qui superbior fuisset horribili supplicio damnavit. Victus enim tibicen in arbore alta suspensus est et cutis, membratim a deo ipso direpta, in spelunca defixa. Quem Nymphae, Fauni Satyrique fletum venerunt et lacrimae , sanguini mixtae, effusae sunt in flumen quod Marsyas appellatum est. <la> <la.la> <la>\n",
      "Summary: Marsyas, etiam ut Oeagnum, Hyagnum, sive Olympum nomine, Phrygium Phrygium fuit: ille superbiae notus, crebris Minervae conpedibus inflatiis auctor: prope montem Idaeum verno tempore, inflata superbia expulsus est. <la>\n",
      "\n",
      "Prompt: <la> Divitia, a decimo saeculo Tuitium (Germanice: \"Deutz\"), est oppidum vetus in dextera (\"falsa\" ut Colonienses ripae sinistrae dicunt) Rheni ripa. Ex anno 1888 est suburbium Coloniae Agrippinae, una octaginta sex urbis regionum. Huic regioni, quae usque ad annum 1888 municipium liberum fuit, circiter 15 269 incolarum sunt. Res gestae. Circa annum 310 Romani pontem trans Rhenum aedificaverunt (Pons Romanus Coloniae Claudiae Arae Agrippinensium), ut citius copias ultra Limitem Germanicum contra Germanos, qui plus plusque rebellabant, ducerent; sed pons etiam mercatu usu fuit. Castellum Divitia e contrario urbis pontis protegendi causa aedificata est. Centum annos post, pons deletus est. Postea Colonia 1400 annos sine ponte fuit. Castellum vetus anno 1003 ab archiepiscopo Heribertus de Colonia in Benedictinorum abbatiam mutatum est. Divitia anno 1583 destructa, 1819 Borussiana facta est. Medio saeculo undevicensimo statio ferriviaria imprimis sacrinariae simul cum officinis et ergasteriis orta est. Pons Hohenzollenorum et alia aedificia saeculi vicensmi. In loco maturioris pontis anno 1911, pons aedificatus cum parte et ferriviaria et ordinaria. Destructo ponte bello universo secundo, pars autocinetorum non est iterum constructa. Pons est autem permagni momenti commeatui ferrivariae, sextem binas orbitas numeramus. Cui autem non pedibus ad coloniam ipsam sed suo vehiculo uti velienti Pons Divitiacum eligendum est. Prope alterum pontem Divitiae, altum aedificium Lufthansae situm. Quo alterior tamen triangulus coloniensis est. Arena Coloniensis et alia. Schola Polytechnica Coloniensis (vulgo: \"FH Köln\") in Divitia sita est. Novissima tamen arena est in qua non gladiatores sed ludricrorum exercendi studentes pugnant, qui non sanguis sed victoriae solae pecuniaeque sitiuntur, et musici ibi autem musicomanibus delectare student. Colonienses eam \"hirneam\" per ridiculum appellant, quia habet arcum maximum transversalem supra visibilem; Divitiae autem hodie paene 16 000 coloniensium incolunt. Nexus externus. Coloniae Agrippinae regiones in circulo urbano Köln-Innenstadt Urbes Romanae in Germania hodierna <la> <la.la> <la>\n",
      "Summary: Divitia, oppidum in regione Coloniae Agrippinae dextrae, saeculo V saeculo V factum est. <la>\n",
      "\n",
      "Prompt: <la> Paradisus in Eden (Hebraice גן בעדן \"gan b Eden\", scil. \"hortus in Eden\"; versione Vulgata \"paradisus voluptatis\" sed Nova Vulgata \"paradisus in Eden\") in mythologia Iudaica fuit locus regionis Eden ubi Iehova hortum seu paradisum creavit; ibi hominem primum misit mulieremque primam coniugem eius introduxit. Originem et geographiam huius horti liber Genesis sic describit: \"Plantavit Iehova hortum in Eden ad orientem, in quo posuit hominem quem formaverat; produxitque Iehova de humo omne lignum visu pulchrum et ad vescendum suave, lignum etiam vitae in medio horti lignumque scientiae boni et mali. Et fluvius egrediebatur ex Eden ad inrigandum hortum, qui inde dividitur in quattuor capita. Nomen uni Phison: ipse est qui circuit omnem terram Hevila, ubi est aurum; et aurum terrae illius optimum est; ibi invenitur \"bedolach\" et lapis \"soham\". Et nomen fluvio secundo Gehon: ipse est qui circuit omnem terram Cus. Nomen vero fluminis tertii Tigris: ipse vadit ad orientem Assyriae. Fluvius autem quartus ipse est Euphrates.\" De origine et confectione libri \"Genesis\" pauca pro certo habentur; nescitur ergo quo tempore haec historia conscripta sit. Hortus autem Iehovae seu Dei (Hebraice גן-יהוה \"Gan-Jahweh\", גן-אלהים \"Gan-Elohim\") sive hortus Eden (Hebraice גן-בעדן \"Gan-Eden\") iam auctoribus Hebraicis saeculorum VI et V a.C.n. bene notus est; Ezechiel enim propheta, qui annis inter 600 et 580 a.C.n. vaticinia declamavit, de arboribus seu \"lignis Eden\" tris locutus est, semel addens \"in Eden fuisti in horto Iehovae\", semel \"Hortum Eden\" adducens, de quo et propheta alius, Ioel, locutus est. Isaias tertius ille de restitutione Hierosolymorum haec praedixit: \"Consolatur enim Iehova Sion, consolatur omnes ruinas eius, et ponit desertum eius quasi Eden et solitudinem eius quasi hortum Iehovae.\" <la> <la.la> <la>\n",
      "Summary: Erat autem ibi paradisus Eden, ubi Isaac hortus creavit, et primus missus est, et uxor eius ad eum adducitur; origo horti et loca describuntur in Genesis quasi orientis Eden, ubi Arborem vitae et Arborem scientiae boni et boni, et Nova Vulgata eam pertinent quasi hortus in Eden. <la>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Prompt summary examples:\")\n",
    "for i in range(5):\n",
    "    print(f\"Prompt: {df_train['prompt'][i]}\\nSummary: {df_train['answer'][i]}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the trained Tokenizer and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "special_tokens :      token\n",
      "0     <en>\n",
      "1     <la>\n",
      "2  <en.la>\n",
      "3  <la.en>\n",
      "4  <la.la>\n",
      "Loaded model from: /Data/AxelDlv/mt5-small-en-la-translation/mt5-small-en-la-translation-final_no_stanza-last_epoch\n",
      "Model parameters: 300,513,664\n",
      "Tokenizer vocab size: 250100\n"
     ]
    }
   ],
   "source": [
    "# Load special tokens and initialize tokenizer\n",
    "special_tokens = pd.read_csv(path_to_special_tokens)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "print(f'special_tokens : {special_tokens}')\n",
    "tokenizer.add_special_tokens({'additional_special_tokens': special_tokens['token'].tolist()})\n",
    "\n",
    "# Load base model (without LoRA yet)\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name).cuda()\n",
    "base_model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Define LoRA Configuration (MUST MATCH training config)\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],  # LoRA layers added to 'q' and 'v' attention components\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_2_SEQ_LM\"\n",
    ")\n",
    "\n",
    "# Wrap base model with LoRA\n",
    "model = PeftModel(base_model, lora_config)\n",
    "model.load_state_dict(torch.load(f\"{checkpoint_path}.pt\", map_location=\"cuda\"))\n",
    "model.to(\"cuda\")\n",
    "\n",
    "# Set model to eval mode\n",
    "model.eval()\n",
    "\n",
    "print('Loaded model from:', checkpoint_path)\n",
    "print(f\"Model parameters: {model.num_parameters():,}\")\n",
    "print(f\"Tokenizer vocab size: {tokenizer.vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = int(np.ceil(len(df_train) / batch_size))\n",
    "total_steps = n_batches * (end_epoch - start_epoch + 1)\n",
    "n_warmup_steps = int(total_steps * 0.05)  # Increased warmup steps for stability\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=n_warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = training_loop(\n",
    "    model, \n",
    "    df_train, \n",
    "    df_test, \n",
    "    tokenizer, \n",
    "    optimizer, \n",
    "    scheduler,\n",
    "    start_epoch, \n",
    "    end_epoch, \n",
    "    batch_size,\n",
    "    checkpoint_dir, \n",
    "    checkpoint_prefix,\n",
    "    print_freq=1, \n",
    "    max_seq_len=max_seq_len,\n",
    "    use_amp=False, \n",
    "    accumulation_steps=1,\n",
    "    column_prompt=\"prompt\", \n",
    "    column_target=\"answer\",\n",
    "    fraction_to_use=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mT5 model and tokenizer\n",
    "max_seq_len = 412                                   # Maximum number of tokens of the input sequence\n",
    "max_new_tokens = 412                                # Maximum number of tokens of the generated sequence\n",
    "model_name = \"/Data/AxelDlv/mt5-small-en-la-translation/mt5-small\"\n",
    "# checkpoint_path = f\"/Data/AxelDlv/mt5-small-en-la-translation/mt5-small-en-la-translation-final_no_stanza-last_epoch\"\n",
    "checkpoint_path = f\"/Data/AxelDlv/mt5-small-la-la-translation/mt5-small-la-la-translation-final-last_epoch\"\n",
    "STANZA = False\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): MT5ForConditionalGeneration(\n",
       "      (shared): Embedding(250105, 512)\n",
       "      (encoder): MT5Stack(\n",
       "        (embed_tokens): Embedding(250105, 512)\n",
       "        (block): ModuleList(\n",
       "          (0): MT5Block(\n",
       "            (layer): ModuleList(\n",
       "              (0): MT5LayerSelfAttention(\n",
       "                (SelfAttention): MT5Attention(\n",
       "                  (q): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                  (v): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                  (relative_attention_bias): Embedding(32, 6)\n",
       "                )\n",
       "                (layer_norm): MT5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): MT5LayerFF(\n",
       "                (DenseReluDense): MT5DenseGatedActDense(\n",
       "                  (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (act): NewGELUActivation()\n",
       "                )\n",
       "                (layer_norm): MT5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1-7): 7 x MT5Block(\n",
       "            (layer): ModuleList(\n",
       "              (0): MT5LayerSelfAttention(\n",
       "                (SelfAttention): MT5Attention(\n",
       "                  (q): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                  (v): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                )\n",
       "                (layer_norm): MT5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): MT5LayerFF(\n",
       "                (DenseReluDense): MT5DenseGatedActDense(\n",
       "                  (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (act): NewGELUActivation()\n",
       "                )\n",
       "                (layer_norm): MT5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_layer_norm): MT5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (decoder): MT5Stack(\n",
       "        (embed_tokens): Embedding(250105, 512)\n",
       "        (block): ModuleList(\n",
       "          (0): MT5Block(\n",
       "            (layer): ModuleList(\n",
       "              (0): MT5LayerSelfAttention(\n",
       "                (SelfAttention): MT5Attention(\n",
       "                  (q): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                  (v): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                  (relative_attention_bias): Embedding(32, 6)\n",
       "                )\n",
       "                (layer_norm): MT5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): MT5LayerCrossAttention(\n",
       "                (EncDecAttention): MT5Attention(\n",
       "                  (q): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                  (v): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                )\n",
       "                (layer_norm): MT5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (2): MT5LayerFF(\n",
       "                (DenseReluDense): MT5DenseGatedActDense(\n",
       "                  (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (act): NewGELUActivation()\n",
       "                )\n",
       "                (layer_norm): MT5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1-7): 7 x MT5Block(\n",
       "            (layer): ModuleList(\n",
       "              (0): MT5LayerSelfAttention(\n",
       "                (SelfAttention): MT5Attention(\n",
       "                  (q): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                  (v): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                )\n",
       "                (layer_norm): MT5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): MT5LayerCrossAttention(\n",
       "                (EncDecAttention): MT5Attention(\n",
       "                  (q): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                  (v): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                )\n",
       "                (layer_norm): MT5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (2): MT5LayerFF(\n",
       "                (DenseReluDense): MT5DenseGatedActDense(\n",
       "                  (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (act): NewGELUActivation()\n",
       "                )\n",
       "                (layer_norm): MT5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_layer_norm): MT5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=512, out_features=250105, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load special tokens and initialize tokenizer\n",
    "special_tokens = pd.read_csv(path_to_special_tokens)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.add_special_tokens({'additional_special_tokens': special_tokens['token'].tolist()})\n",
    "\n",
    "# Load base model (without LoRA yet)\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name).cuda()\n",
    "base_model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Define LoRA Configuration (MUST MATCH training config)\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],  # LoRA layers added to 'q' and 'v' attention components\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_2_SEQ_LM\"\n",
    ")\n",
    "\n",
    "# Wrap base model with LoRA\n",
    "model = PeftModel(base_model, lora_config)\n",
    "model.load_state_dict(torch.load(f\"{checkpoint_path}.pt\", map_location=\"cuda\"))\n",
    "model.to(\"cuda\")\n",
    "\n",
    "# Set model to eval mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: <la> Hesiodus (floruit saeculo 8 vel 7 a.C.n.) fuit poeta epicus Graecus qui carmina didactica composuit. Vita. Primus poeta fuit qui aliquid de se in carminibus tradideritː nam Homerus omnino siluit. Eius parentes Cyma in Aeolide oriundi erant, sed pater Ascram Boeotiae, sub Helicone sitam, migravit. Agricola ibi fuit, itidem et Hesiodus ipse, ut in \"Operibus\" (633—640) ait. Persae fratri, quem virum nequam esse iudicabat quocum lites plures habebat, eodem carmine praecepta dat. De poetica arte ita in \"Theogonia\" (22—34) tradebatː sibi in Helicone monte greges pascenti Musas sponte occurrisse et canere docuisse. Deinde Chalcidem in Euboeam, ut dicit in \"Operibus\" (654—655), ad certamen poeticum venit et vicit. An revera adversarius eius Homerus ipse tum fuerit, ut fabula de hoc certamine tempore seriore composita narrabat, dubitare licet. De morte et sepulchro. Mortuus est Ascrae, vel in Naupacto. Ascra a Thespiensibus deleta incolae Orchomenum abierunt et ossa Hesiodi eodem auferunt, ut Aristoteles in tractatu de civitate Orchomenia aiebat. Pausanias sepulchrum illius cum inscriptione Orchomeni vidit Orchomenii se ossa Hesiodi secundum oraculum in terra Naupactia inventa unde transtulisse affirmabant. Plutarchus autem et Tzetzes fabulam narrant de Hesiodo in Locride Ozolia occiso et in Naupacto sepulto. Locum Naupactios non aperire, ne Orchomenii ossa raperent, Tzetzes narrat. Memento tamen praeter quae ipse poeta in versibus suis cecinerit cetera omnia maxime dubia esse. Opera. Boeoti autem sub Helicone terram colentes Hesiodum nihil nisi \"Opera\" scripsisse nec initio \"Operum\" de Camenis decem primos versus Hesiodeos esse affirmabant et tabulam aeneam cum vero textu \"Operum\" monstrabant, ut Pausanias dicit. <la> <la.la> <la>\n",
      "Generated Text: Hesiodus (floruit saeculo 8 et 7 a.C.n.) fuit poeta Graecus in Aeolide oriundis, et pater Ascram Boeotiae, in Helicone sitam erat.\n",
      "--------------------------------------------------------------------------------\n",
      "Prompt: <la> Ars oecologica, vel ars circumiectorum, est nomen generale quod significat varietatem usuum artificium quae accessus historicos ad naturam in arte captam ac recentioria operum genera oecologica et a rebus civilibus impulsa amplectitur. Verbum \"ars oecologica\" res oecologicas saepe comprehendit, sed eis proprium non est. Satis flexibile est ut primam huius motus historiam agnoscere possit (qui saepe notiones artis plus quam notiones oecologicas tractabat), atque artem cui sunt negotia satis turbatoris plebi et ars quae plerumque artificis coniunctionem cum natura celebrat, copiis rerum naturalibus utens. Verbum \"ars oecologica\" in variis contextibus adhibetur: uti potest ad spectandam artem quae mundum naturalem describit, artem quae personale celebrat negotium cum mundo naturali (\"ars in natura\"), et usus artificium oecologicorum, quorum opus res circiumiectorum recte tractat, per educationem de mundo naturali, vel reficiendum mundum naturalem. Aviva Rahmani, artifex oecologica, aestimat: \"Ars oecologica est ratio artis, saepe cum physicis, designatoribus urbanis, architectis, et aliis conlaborans, quae rectam interventionem in deteriore circumiectorum statu efficit. Artifex in ratione illa saepe est procurator ducens.\" Media et activitates quas artifices oecologici adhibentur sunt diversissimae, inter quas pictura, photographia, ars exsecutiva, experimenta quae lucem et sonos adhibeant, sculptura, oecofeminismus, magnae exhibitiones terrestres vel opera terrena, ars creationis magnarum installationum in terra conditarum res architecturae, et inventa scientifica. Informatio scientifica saepe in talibus operibus constituitur. Historia: pictura et repraesentatio scaenarum. Prima historica artis oecologicae exempla ex repraesentatione et pictura scaenarum nata sunt. Artifices, cum in situ pingerent, coniunctionem cum circumiectis et suo caelo penitus evolverunt et has observationes attentas in suis textilibus tulerunt. Picturae Ioannis Constable caelum in natura accuratissime depingunt. Series Londiniensis Claudii Monet coniunctionem artificis cum circumiectis etiam repraesentat: \"Scaena mihi exsistit per se, quod aspectus semper commutatur; sed atmosphaera circumiecta eum ad vitam revocat, ad aerem et lucem, qui mihi continenter variant; sola atmosphera circumiecta pretium verum rebus dat.\" Nexus externi. <la> <la.la> <la>\n",
      "Generated Text: Ars oecologica, est nomen generalum, quod archaeologa est, et eae in arte captam, quae subiecta artem est.\n",
      "--------------------------------------------------------------------------------\n",
      "Prompt: <la> Coronatio regis Philippi II (1179) Sacrum sive coronamentum regis Philippi II Francorum anno 1179 celebratum est, patre Ludovico VII etiam vivente sed graviter aegrotante. Rex Ludovicus VII anno 1179 ineunte concilium Lutetiae convocavit ubi statutum est filium suum Philippum, annum quartum decimum agens, iuxta patrem coronatum iri. Coronamentum Remis die 15 Augusti eiusdem anni celebrare statutum est. Mox autem Philippus iuvenis dum in silva Compendiensi venandi causa vagat perditus est; a rustico quodam ad parentes conductus est, sed post reditum aegrotavit. Pater Cantuariam mense Augusto properavit, sepulchri Thomae a Becket peregrinator. Lutetiam revenit sed apoplexi ictus est. Coronamentum igitur principis, propter morbum suum postpositum, iam propter patris morbum subito celebratum est, die 1 Novembris 1179, ut ipse statim pro patre imperaret. Coronamentum in Ecclesia Cathedrali Remensi actum est, praeside Guillelmus Campaniensis archipiscopo Remensi, Philippi avunculo et praeceptore. Adstetit Philippus comes Flandrensis cum genero Balduino V comite Hononiensi; Philippus Flandrensis, iam consiliarius principis, matrimonium huius cum Isabella Balduini filia aut iam suadebat aut mox suaserit. Adsteterunt etiam tres filii regis Henricus II, scilicet Henricus rex iunior, Ricardus rex futurus, Galfridus dux Britanniae. Rex Ludovicus, pater principis, a sacris ob paralysim aufuit. Coronamento celebrato, rege a populo verbis \"Vivat rex! Vivat rex!\" acclamato, epulum nobilibus datum est. Bibliographia. <la> <la.la> <la>\n",
      "Generated Text: Coronatio regis Philippi II, anno 1179 celebratum est, filius Philippus VII, etiam consilium in Lutetiae convocavit.\n",
      "--------------------------------------------------------------------------------\n",
      "Prompt: <la> Metatypia est talis mutatio morphosyntactica et semantica, quae per contactum socialem locutorum multilinguium efficiatur. Nomen metatypiae (\"metatypy\") a linguista Malcolm D. Ross factum est, qui terminum hac definitione describit (1999:7.1): [Metatypia est] mutatio generis morphosyntactici et organizationis grammaticae [et exemplarium semanticorum] quae lingua ob bilingualismum eius loquentium in alia lingua patitur. Haec mutatio interpretatione grammatica perducitur; hoc est constructionalem imitari significationem ex lingua mutata ac novas novare structuras, materiam hereditate exceptam ad eas exprimendas adhibens. Comitans huius redintegrationis constructionum grammaticarum res saepe est redintegratio vel creatio paradigmatum functorum grammaticorum. . . . Usitate, lingua quae metatypiam patitur (\"lingua immutata\") identitatem suorum loquentium exprimit, cum lingua quae \"exemplar metatypicum\" praebet sit \"lingua inter communia.\" Loquentes linguae immutatae commune constituunt tam strictum ut ei suam identitatem separatam et suam linguam ut signum illius identitatis bene sentiunt, sed nonnulli tantum loquentes bilingues lingua inter communia tam late utuntur ut eis magis commoda est quam lingua commune significanti. Ross (2002) has mutationes metatypicas cognoscit: Ross praeterea cognoscit denuo constitionem semanticam ante restructurationem syntacticam fieri. Mutationes syntacticae hoc ordine fiunt: (i) sententia/clausa, (ii) phrasis, (iii) verbum. Hic sunt nonnullae linguae quae metatypiam passae sunt: Exemplum: Takia Papuanizata et Waskia. Exemplum a Ross datum (1999) est papuanizatio linguae Takiae (rami occidentalis familiae Oceanicae) ob momentum ex vicina lingua Waskia (familiae Madang, phyli Transnovaguinei). Hic, in notione Rossiana, Takia est \"lingua modificata\"; Waskia, \"lingua inter communia.\" Waskia, autem, non videtur a Takia magnopere mota esse. Ambae linguae in usu in Lingua Karkar sunt. Effectu mutationis metatypicae Takia usitate Waska ad verbum convertit, ut hic: Hoc par structurarum syntacticarum et semanticarum huic conversioni ad verbum facultatem facit. Inter mutationes grammaticas quas Takia patitur sunt: Mutationes diffusionales in Takia solum per metatypiam sunt; quod significat Takiam suam phonologiam non mutavisse et paene nulla verba a Waskia mutuata habere. <la> <la.la> <la>\n",
      "Generated Text: Metatypia est synonymum morphosyntactica et semantica, quae vocabula grammaticae est, quod lingua eorum loquitur, a linguis linguistica est.\n",
      "--------------------------------------------------------------------------------\n",
      "Prompt: <la> Crux Sancti Augustini est monumentum lapideum in Cantia positum, intra saeptum in meridiano Viae Cottingtonianae latere, ab occidente Cliffs End, in Sinu Pegwell insulae Thaneti, circa 2 milia ab occidente Ramsgate, 3 milia a septentrionibus Richborough Roman Fort, et 12 milia ab oriente Cantuariae, in paroechia Minster. Crux anno 1884 posita est ad Augustinum Cantuariensem in Angliam anno 597 advectum commemorandum. Historia. Gregorius I Papa anno 595 Augustinum, quemdam monachum, selegit, ut missionem in Angliam duceret ad Saxones in Regno Cantuariorum ad Christianitatem convertendos. Haec legatio, missio Gregoriana appellata, in Cantiam anno 597 appulsa est. Beda in \"Historia ecclesiastica gentis Anglorum\" scripsit: Est autem ad orientalem Cantiae plagam Tanatos insula non modica, id est magnitudinis iuxta consuetudinem aestimationis Anglorum, familiarum DCrum, quam a continenti terra secernit fluuius Uantsumu, qui est latitudinis circiter trium stadiorum, et duobus tantum in locis est transmeabilis; utrumque enim caput protendit in mare. In hac ergo adplicuit seruus Domini Augustinus, et socii eius, uiri, ut ferunt, ferme XL. Acceperunt autem, praecipiente beato papa Gregorio, de gente Francorum interpretes. Quod interpretatum significat Augustinum in Ebbsfleet egressum fuisse. Signum. Iuxta crucem stat lamina metallica, inscriptionem ferens ab Henrico Liddell, Decano Aedium Christi Oxoniae (1855–1891), nostra lingua scriptam, quae congressum Augustini et Ethelberti, primam Augustini homiliam, et sequentem Christianitatis per Angliam expansionem commemorat. Alia lamina metallica inscriptionem Anglice conversam monstrat. <la> <la.la> <la>\n",
      "Generated Text: Crux Sancti Augustini est monumentum lapideum in Cantia, in meridiano Viae Cottingtonianae, circa 2 milia ab occidente Cliffs End, et a septentrionibus Richborough Roman Fort, iuxta ecclesiam in Angliae.\n",
      "--------------------------------------------------------------------------------\n",
      "Prompt: <la> Corona Borealis constellatio haud ampla in caelo septentrionali sita est. Quae inter constellationes Herculem atque Arcturum videri potest. Stellae Coronae Borealis semicirculum formant. Stella lucidissima Gemma appellata magnitudine 2m fulget, ceterae autem quartae tantum magnitudinis sunt. Apud alias gentes haec constellatio alias res significat, exempli causa apud Arabes \"mendici lanx\" est, apud Sinenses \"pecuniae catena\". In Mythologia Graeca constellatio significat coronam gemmis ornatam Ariadnes, filiae regis Mini Cretensis. Ariadne Theseum iuvit Minotaurum superantem. Nam Theseus filum ab ei accepit, quocum viam e labyrintho ducentem repperit, quo in labyrintho belua capta erat. Stellae. Si plus cognoscere vis, vide etiam Stellae Coronae Borealis. Stella lucidissima Gemma (etiam Alphecca appellata) circiter 80 spatia lucis annuae a Sole remota est. Illa stella candida vel caerulea e classe spectrali A0 V est. Nusacana, quae luminositate secundum ordinem tenet, 114 spatia lucis annuae remota e classe spectrali F0 V est. In Corona Boreali etiam nonnullae stellae duplices sitae sunt, quae quidem non nisi telescopio singillatim spectari possunt. Systema η CrB 59 spatia lucis annuae remota est. Hoc in systemate duae stellae luteae classis spectralis G1 seu G3 intra 41,5 annos circum mediam gravitatem revolvuntur. Distantia stellarum a Terra 0,7 (anno 2000) ac 0,4 (anno 2020) arcus secundos est. \"R Coronae Borealis\" nomen dedit gregi stellarum mutantium, quae luminositatem irregulariter mutare solent: Nonnumquam luminositas celeriter decrescit, post temporis spatium inopinatum paulatim recrescit. Viri docti e luce scrutata cognoverunt stellarum superficiem plura helii et carbonii continere. Inde hae stellae irregulariter partes earum sphaeram gasorum expellere putantur, ut ex carbonii particulis fuligo fiat, quae lucem non perire sinit. Hac nube dissoluta stella rursus lucidior facta sit. Nexus externi. Constellationes nominibus Latinis digestae Constellationes abbreviationibus digestae Zodiacus <la> <la.la> <la>\n",
      "Generated Text: Corona Borealis constellatio in caelo septentrionali sita est. Quae stellae Coronae borealis, a eo erat.\n",
      "--------------------------------------------------------------------------------\n",
      "Prompt: <la> Sanctus Cyprianus alias Thascius Caecilius Cyprianus (ca. 200–258), fuit episcopus Carthaginiensis, doctor Ecclesiae et apologeta necnon martyr. Vita et passio. Natus est in Africa die ignoto ca. annum 200. Primum fuit rhetor Carthagine. Iam matura aetate conversus est ad Christum; presbyter ordinatus est, dein episcopus Carthaginiensis (248 vel 249). Tempore persecutionum, primum damnatus est exsilio (mense Augusto 257), postea, die 14 Septembris 258, securi feritus. Haec leguntur in \"Martyrologio Romano\" (14 Septembris 2001): \"Carthagine, passio sancti Cypriani, episcopi, sanctitate et doctrina clarissimi, qui funestissimis temporibus Ecclesiam optime rexit, confessores fidei in aerumnis firmauit et, Valeriano et Gallieno principibus, post durum exsilium, coram frequentissimo populo a proconsule gladio animaduerti iussus martyrium consummauit. eius memoria perendie celebratur.\" De vita eius a diacono Pontio scriptum est, sub titulo \"Vita Cypriani.\" Eius passionis acta proconsularia authentica servata sunt. (Textus) Opera. Sanctus Cyprianus multos tractatus scripsit et litteras, ad Christianismum defendendum et ad fidem Christifidelium tuendam. Usque ad tempus Sancti Augustini, praecipuus erat scriptor ecclesiasticus Latinus. Eius opera multi legerunt. Prudentius poeta stylum eius celebravit in poemate 13 operis cui nomen est \"Peristephanon liber\": Punica terra tulit quo splendeat omne quidquid usquam est, inde domo Cyprianum, sed decus orbis et magistrum. Est proprius patriae martyr, sed amore et ore noster; incubat in Libya sanguis, sed ubique lingua pollet, sola superstes agit de corpore, sola obire nescit, dum genus esse hominum Christus sinet et vigere mundum. Dum liber ullus erit, dum scrinia sacra litterarum, te leget omnis amans Christum, tua, Cypriane, discet. Spiritus ille Dei, qui fluxerat auctor in prophetas, fontibus eloquii te caelitus actus irrigavit. Sanctus Hieronymus de eo scripsit in opere \"De viris illustribus,\" 67: \"Huius ingenii superfluum est indicem texere, cum sole clariora sint eius opera.\" Cultus. Corpus Sancti Cypriani sepultum est Carthagine, in coemeterio Macrobii Candidiani, apud viam Mappalensium, ubi cultus eius incepit die 14 Septembris 258. Pace ecclesiae reddita, ibi exstructa est basilica. \"Mensa Cypriani\" erecta est in agro Sextii, ubi passus erat. Festum sancti Cypriani apparet in omnibus calendariis liturgicis antiquissimis. Sanctus Cyprianus memoratur in canone Romano sanctae Missae. <la> <la.la> <la>\n",
      "Generated Text: Sanctus Caecilius Cyprianus, episcopus Carthaginiensis, doctore Ecclesiae et apologetae, et doctrinae aetate persecutione est.\n",
      "--------------------------------------------------------------------------------\n",
      "Prompt: <la> -3 \" huius rei maxime dubia est. Corrige si potes. Vide .\" Coordinata: Academia Scientiarum et Humanitatum Israëlis Hierosolymis anno 1961 condita a civitate Israeli ut communicationem foveat inter scholasticos scientiarum et humanitatum in consilium gubernio investigationis gradus nationis et praestantias promoveat. Confecta est ex 102 disciplinis in Israel conspicuis. Locus est proximus sedis Praesidis et Consilii Altae Educatione in area quadrata Albert Einstein. In scientiis, Academia commissos faeneratur in discipliniis Israeli geoligiis, floriis, fauniis, et accommodat physicos investigando in commissibus inter gentium sicut alta energia physica in CERN et synchrotronica radiatione in Facilitate Synchrotronica Radiatione Europeane. Israel summam habet conctractionis physicorum machinatorumque in in gentium. Israel summam habet conctractionis physicorum machinatorumque in in gentium. In Humanitate, Investigationibus studibusque copiae praebentur Tanachi, Talmudo, Historiae Iudaicae, et prosae poesique Iudiaicae. Academia, Einstein Fellowships fund annonas $53 millionis administrat at alia annonas affinitatibus inter physicos inter gentes et communitatem academicam Israeli et aliis donationes inquisitionibus ex Israel Science Fund inquisitioni spatio, Wolf Foundation et Fulks Fund medica inquisitioni. Academia etiam Israel Academic Center in Cairo curat, qua scholares Israeli adiuvat, investigando Aegypto et sua cultura et consortium academicium aegyptium commodat. Academia spectatorem statum tenet in Fundatione Europeanis Scientiae et, programmas gerit commutationis cum Societate Britannicis Regalis, Academia Britannicis, Academia Suecis et Concilio Nationalis Investigationis Singapurae. <la> <la.la> <la>\n",
      "Generated Text: Academia Scientiarum et Humanitatum Israëlis Hierosolymis anno 1961 condita est a civitate Israeli in consilium gubernio investigationis academicorum et scientiae et humanitarum eorum, et disciplinis in Aegypto.\n",
      "--------------------------------------------------------------------------------\n",
      "Prompt: <la> Cornubia vel Cornwallia sive Cornvallia (Anglice \"Cornwall\"; Cornubice \"\") est ducatus insulae Britanniae, intra Britanniarum Regnum sita, paeninsula Mare Celticum a septentrionibus et occidentibus, Oceanum Britannicum a meridie, et Devoniam ab oriente praeter Tamarus flumen attingens. Sillinae insulae sunt archipelagus, comitatús historici Cornubiae pars, ad occidentem versus in Oceano Atlantico iacens, quarum insularum distantissimus est Bishop Rock, rupis pharo munita. Pharis etiam distinguuntur rupes periculosae Wolf Rock et the Longships. Truro, urbs parva, media paeninsula surgens, est comitatús sedes administrativa necnon episcopalis in Ecclesia Anglicana. Selectio oppidorum. Inter oppida iuxta mare iacentes enumerare oportet Bude, Boscastle, Tintagel, Port Isaac, Padstow, Newquay, St Agnes, Perranporth, Hayle, villa Sanctae Ivae, St Just in Penwith et Sennen ad oram maritimam septentrionalem; Mousehole, Penzance, Marazion, Perranuthnoe, Porthleven, Lizard Town, Falmuthum, Penryn, Flushing, Mylor, St Mawes, Veryan, Mevagissey, Polruan, Fowey, Polperro, West Looe, East Looe et Saltash ad meridianam. Oppidorum mediterraneorum praecipua sunt Launceston, Bosvena, St Austell, Redruth, Camborne et Helston. Adduntur minora St Germans, Callington, Liskeard, Lostwithiel, Tregony, Grampound, Probus, Wadebridge, Camelford, Kilkhampton, Stratton, St Columb Major, Mitchell et vici olim frequentati, hodie modestissimi Cargoll, Goldsithney, Insworke, Lanreath, Lawhitton, Lelant, Menheniot, Methleigh, Paul, Pelynt, Penknight, Sheviock, St Buryan, St Erme, St Newlyn East, St Stephen in Brannel, Summercourt, Trematon, Tywarnhayle, Week St Mary. Oppidum parvum Hugh Town, in insula St Mary's stans, est caput insularum Sillinarum. Insula sacra S. Michaeli dicata iuxta Marazion iacet. Geographia. Ad oras Cornubiae reperiuntur extrema Britanniae promuntoria omnis tam meridianum, videlicet Ocrinum, quam occidentale, videlicet Antivestaeum. Inter flumina minora Cornubiae sunt Camula, Fal, Fowey, Hayle, Looe et Ottery. Montes altissimi sunt Brown Willy et Rough Tor. Inter locos archaeologicos praecipuos enumerare oportet Chysauster et Carn Euny, oppida antiqua, ac Caer Bran, Castellum Chûn, et Castellum an Dinas, castra collina. Cornubia divisa erat in partes decem (Anglice: \"hundreds\"). Lingua. Cornubienses lingua Cornubica olim utebantur, sed a saeculo fere duodevicensimo haec lingua exstincta est. Hodie quidam rursus favent; anno 2010, homines circiter 2000 Cornubice loqui possunt. Nexus externi. Comitatus Angliae geographici Comitatus Angliae sollemnes <la> <la.la> <la>\n",
      "Generated Text: Cornubia, Cornwallia, est insulae Britanniae, a septentrionibus et occidentibus, Oceanum Britannicum, in Oceano Atlantico, et Devoniam ab oriente.\n",
      "--------------------------------------------------------------------------------\n",
      "Prompt: <la> Ranunculus auricomus est species collectiva \"Ranunculi\", generis plantarum angiospermarum, in zona temperata Europae et Asiae crescens. Descriptio. A reliquis congeneris \"R. auricomus\" recedit: \"Ranunculus auricomus\", herba perennis, in pascuis, pratis, ad vias vel ad margines silvarum crescit. Taxinomia. De specie et loco eius intra genus. \"Ranunculo auricomo\" nomen Carolus Linnaeus imposuit. Holotypus speciei forsitan in Batavia collectus est, sed de hoc non constat. \"Ranunculus auricomus\" tamquam typus generis sui a Nathanaele Lord Britton et Addisone Brown designatus est, sed typificatio haec postea reversa est, \"Ranunculo acri\" in typum generis selecto. Unde et apud auctores typificationem antiquam sequentes sectio \"R. auricomum\" continens \"Ranunculus\" nuncupatur, sectio vero \"R. acrem\" continens \"Acris\"; e contra, iuxta typificationem hodiernam sectio \"R. auricomum\" continens \"Auricomus\" appellanda est, sectio vero \"R. acrem\" continens \"Ranunculus\". De microspeciebus. Populationes \"Ranunculi auricomi\" inter se multum differunt, in eodem quoque loco vero characteres immutabiles exhibent, cuius phaenomeni inusitati ratio est quod haec plantae facultatem reproductionis sexualis amiserint, prolemque per apomixin generent; species ergo collectiva e permultis microspeciebus consistit. Unde et nomen \"R. auricomi\" referre potest: Microspecies \"Ranunculi auricomi\" inter se characteribus haud raro minimis difficilibusque visu differunt. In aliquot regionibus microspecies haec descriptae sunt, ut in nonnullis partibus Sueciae (praesertim in Sudermannia), Fenniae, Angliae, et Poloniae, in Bavaria, Saxonia, Alsatia, Austria et Hispania. In multis vero aliis regionibus ignotae remanent. Microspecies in sola Scandinavia, ubi plurimae, certe plus quam 600 sunt; additis ergo microspeciebus Europae mediae et occidentalis (exempli gratia 35 e Saxonia, 30 ex Alsatia, 58 ex Anglia, 17 ex Hispania), numerus microspecierum numerum omnium aliarum specierum generis \"Ranunculi\" excedit. <la> <la.la> <la>\n",
      "Generated Text: Ranunculus auricomus, species angiospermarum, in regione temperata Europae et Asiae crescit.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_data_ = df_test[:10]\n",
    "\n",
    "outputs = inference_from_csv(model, test_data_, tokenizer, batch_size=8, max_seq_len=412, column_prompt=\"prompt\", use_amp=True)\n",
    "for item in outputs:\n",
    "    print(\"Prompt:\", item[\"prompt\"])\n",
    "    print(\"Generated Text:\", item[\"generated_text\"])\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "plot_training(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss curve\n",
    "plot_training(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on ROUGE & BERTScore (Summarization Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;la&gt; Hesiodus (floruit saeculo 8 vel 7 a.C.n.)...</td>\n",
       "      <td>Hesiodus, circa 4-11 a.C.n. natus, est poeta G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;la&gt; Ars oecologica, vel ars circumiectorum, e...</td>\n",
       "      <td>Verbum \"oecologicum Ars,\" sive \"circumiectum\" ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;la&gt; Coronatio regis Philippi II (1179) Sacrum...</td>\n",
       "      <td>In anno 1179 rex Philippus II Francorum sacrae...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;la&gt; Metatypia est talis mutatio morphosyntact...</td>\n",
       "      <td>Metatypia, a Malcolm D. Ross anno 1999 coincta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;la&gt; Crux Sancti Augustini est monumentum lapi...</td>\n",
       "      <td>Saint Augustine Church, monumentum lapideum, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>&lt;la&gt; Philosophia neoscholastica, vulgo thomism...</td>\n",
       "      <td>Ratio Neo-Scholatica, etiam vocabulo Neo-Schol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>&lt;la&gt; Lingua bavarica est lingua cum multis var...</td>\n",
       "      <td>Anglice lingua meridiana, cum dialecticiis mul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>&lt;la&gt; Appius Claudius Ap.f. Crassus Inregillens...</td>\n",
       "      <td>Senatoris Romanus Appius Claudius A.f. Crassus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>&lt;la&gt; %; left: %; height: 0; width: 0; margin: ...</td>\n",
       "      <td>Calleva Atrebatum, civitas Romana in Brittania...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>&lt;la&gt; Valie Export (natus die 17 Maii 1940 Lent...</td>\n",
       "      <td>Anno 1967, laborantem Hungaricum Lentia opus c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prompt  \\\n",
       "0    <la> Hesiodus (floruit saeculo 8 vel 7 a.C.n.)...   \n",
       "1    <la> Ars oecologica, vel ars circumiectorum, e...   \n",
       "2    <la> Coronatio regis Philippi II (1179) Sacrum...   \n",
       "3    <la> Metatypia est talis mutatio morphosyntact...   \n",
       "4    <la> Crux Sancti Augustini est monumentum lapi...   \n",
       "..                                                 ...   \n",
       "245  <la> Philosophia neoscholastica, vulgo thomism...   \n",
       "246  <la> Lingua bavarica est lingua cum multis var...   \n",
       "247  <la> Appius Claudius Ap.f. Crassus Inregillens...   \n",
       "248  <la> %; left: %; height: 0; width: 0; margin: ...   \n",
       "249  <la> Valie Export (natus die 17 Maii 1940 Lent...   \n",
       "\n",
       "                                                answer  \n",
       "0    Hesiodus, circa 4-11 a.C.n. natus, est poeta G...  \n",
       "1    Verbum \"oecologicum Ars,\" sive \"circumiectum\" ...  \n",
       "2    In anno 1179 rex Philippus II Francorum sacrae...  \n",
       "3    Metatypia, a Malcolm D. Ross anno 1999 coincta...  \n",
       "4    Saint Augustine Church, monumentum lapideum, i...  \n",
       "..                                                 ...  \n",
       "245  Ratio Neo-Scholatica, etiam vocabulo Neo-Schol...  \n",
       "246  Anglice lingua meridiana, cum dialecticiis mul...  \n",
       "247  Senatoris Romanus Appius Claudius A.f. Crassus...  \n",
       "248  Calleva Atrebatum, civitas Romana in Brittania...  \n",
       "249  Anno 1967, laborantem Hungaricum Lentia opus c...  \n",
       "\n",
       "[250 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "      <th>generated_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hesiodus (floruit saeculo 8 vel 7 a.C.n.) fui...</td>\n",
       "      <td>Hesiodus, circa 4-11 a.C.n. natus, est poeta G...</td>\n",
       "      <td>Hesiodus (floruit saeculo 8 vel 7 a.C.n. Et ig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ars oecologica, vel ars circumiectorum, est n...</td>\n",
       "      <td>Verbum \"oecologicum Ars,\" sive \"circumiectum\" ...</td>\n",
       "      <td>Ars oecologica, vel ars circumiectorum, est no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronatio regis Philippi II (1179) Sacrum siv...</td>\n",
       "      <td>In anno 1179 rex Philippus II Francorum sacrae...</td>\n",
       "      <td>Coronatio regis Philippi II (1179) Benedictus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Metatypia est talis mutatio morphosyntactica ...</td>\n",
       "      <td>Metatypia, a Malcolm D. Ross anno 1999 coincta...</td>\n",
       "      <td>Metatypia est talis mutatio morphosyntactica e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Crux Sancti Augustini est monumentum lapideum...</td>\n",
       "      <td>Saint Augustine Church, monumentum lapideum, i...</td>\n",
       "      <td>Crux Sancti Augustini est monumentum lapideum ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Philosophia neoscholastica, vulgo thomismus n...</td>\n",
       "      <td>Ratio Neo-Scholatica, etiam vocabulo Neo-Schol...</td>\n",
       "      <td>Philosophia neoscholastica, vulgo thomismus ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Lingua bavarica est lingua cum multis varieta...</td>\n",
       "      <td>Anglice lingua meridiana, cum dialecticiis mul...</td>\n",
       "      <td>Lingua bavarica est lingua cum multis varietat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Appius Claudius Ap.f. Crassus Inregillensis S...</td>\n",
       "      <td>Senatoris Romanus Appius Claudius A.f. Crassus...</td>\n",
       "      <td>Appius Claudius Ap.f. Quod igitur, quod in eo, ae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>%; left: %; height: 0; width: 0; margin: 0; p...</td>\n",
       "      <td>Calleva Atrebatum, civitas Romana in Brittania...</td>\n",
       "      <td>%; left: margin: 0; width: 1em; box-shadow: 8p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Valie Export (natus die 17 Maii 1940 Lentiae ...</td>\n",
       "      <td>Anno 1967, laborantem Hungaricum Lentia opus c...</td>\n",
       "      <td>Valie Export (natus die 17 Maii 1940 Lentiae n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prompt  \\\n",
       "0     Hesiodus (floruit saeculo 8 vel 7 a.C.n.) fui...   \n",
       "1     Ars oecologica, vel ars circumiectorum, est n...   \n",
       "2     Coronatio regis Philippi II (1179) Sacrum siv...   \n",
       "3     Metatypia est talis mutatio morphosyntactica ...   \n",
       "4     Crux Sancti Augustini est monumentum lapideum...   \n",
       "..                                                 ...   \n",
       "245   Philosophia neoscholastica, vulgo thomismus n...   \n",
       "246   Lingua bavarica est lingua cum multis varieta...   \n",
       "247   Appius Claudius Ap.f. Crassus Inregillensis S...   \n",
       "248   %; left: %; height: 0; width: 0; margin: 0; p...   \n",
       "249   Valie Export (natus die 17 Maii 1940 Lentiae ...   \n",
       "\n",
       "                                                answer  \\\n",
       "0    Hesiodus, circa 4-11 a.C.n. natus, est poeta G...   \n",
       "1    Verbum \"oecologicum Ars,\" sive \"circumiectum\" ...   \n",
       "2    In anno 1179 rex Philippus II Francorum sacrae...   \n",
       "3    Metatypia, a Malcolm D. Ross anno 1999 coincta...   \n",
       "4    Saint Augustine Church, monumentum lapideum, i...   \n",
       "..                                                 ...   \n",
       "245  Ratio Neo-Scholatica, etiam vocabulo Neo-Schol...   \n",
       "246  Anglice lingua meridiana, cum dialecticiis mul...   \n",
       "247  Senatoris Romanus Appius Claudius A.f. Crassus...   \n",
       "248  Calleva Atrebatum, civitas Romana in Brittania...   \n",
       "249  Anno 1967, laborantem Hungaricum Lentia opus c...   \n",
       "\n",
       "                                        generated_text  \n",
       "0    Hesiodus (floruit saeculo 8 vel 7 a.C.n. Et ig...  \n",
       "1    Ars oecologica, vel ars circumiectorum, est no...  \n",
       "2    Coronatio regis Philippi II (1179) Benedictus ...  \n",
       "3    Metatypia est talis mutatio morphosyntactica e...  \n",
       "4    Crux Sancti Augustini est monumentum lapideum ...  \n",
       "..                                                 ...  \n",
       "245  Philosophia neoscholastica, vulgo thomismus ne...  \n",
       "246  Lingua bavarica est lingua cum multis varietat...  \n",
       "247  Appius Claudius Ap.f. Quod igitur, quod in eo, ae  \n",
       "248  %; left: margin: 0; width: 1em; box-shadow: 8p...  \n",
       "249  Valie Export (natus die 17 Maii 1940 Lentiae n...  \n",
       "\n",
       "[250 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove every special token from the tokenizer ie every <...>, using regex\n",
    "pattern = r\"<.*?>\"\n",
    "test_data_ = inference_from_csv_adding_column(model, \n",
    "                                              df_test, \n",
    "                                              tokenizer, \n",
    "                                              batch_size=8, \n",
    "                                              max_seq_len=max_new_tokens, \n",
    "                                              column_prompt=\"prompt\",\n",
    "                                              new_column=\"generated_text\", \n",
    "                                              use_amp=True)\n",
    "test_data_ = test_data_.replace(to_replace=pattern, value=\"\", regex=True)\n",
    "test_data_ = test_data_.replace(to_replace=r\"\\n\", value=\" \", regex=True)\n",
    "test_data_ = test_data_.replace(to_replace=r\"\\s+\", value=\" \", regex=True) # remove multiple spaces\n",
    "test_data_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_['prefix'] = \"la.la\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "      <th>generated_text</th>\n",
       "      <th>prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hesiodus (floruit saeculo 8 vel 7 a.C.n.) fui...</td>\n",
       "      <td>Hesiodus, circa 4-11 a.C.n. natus, est poeta G...</td>\n",
       "      <td>Hesiodus (floruit saeculo 8 vel 7 a.C.n. Et ig...</td>\n",
       "      <td>la.la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ars oecologica, vel ars circumiectorum, est n...</td>\n",
       "      <td>Verbum \"oecologicum Ars,\" sive \"circumiectum\" ...</td>\n",
       "      <td>Ars oecologica, vel ars circumiectorum, est no...</td>\n",
       "      <td>la.la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronatio regis Philippi II (1179) Sacrum siv...</td>\n",
       "      <td>In anno 1179 rex Philippus II Francorum sacrae...</td>\n",
       "      <td>Coronatio regis Philippi II (1179) Benedictus ...</td>\n",
       "      <td>la.la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Metatypia est talis mutatio morphosyntactica ...</td>\n",
       "      <td>Metatypia, a Malcolm D. Ross anno 1999 coincta...</td>\n",
       "      <td>Metatypia est talis mutatio morphosyntactica e...</td>\n",
       "      <td>la.la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Crux Sancti Augustini est monumentum lapideum...</td>\n",
       "      <td>Saint Augustine Church, monumentum lapideum, i...</td>\n",
       "      <td>Crux Sancti Augustini est monumentum lapideum ...</td>\n",
       "      <td>la.la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Philosophia neoscholastica, vulgo thomismus n...</td>\n",
       "      <td>Ratio Neo-Scholatica, etiam vocabulo Neo-Schol...</td>\n",
       "      <td>Philosophia neoscholastica, vulgo thomismus ne...</td>\n",
       "      <td>la.la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Lingua bavarica est lingua cum multis varieta...</td>\n",
       "      <td>Anglice lingua meridiana, cum dialecticiis mul...</td>\n",
       "      <td>Lingua bavarica est lingua cum multis varietat...</td>\n",
       "      <td>la.la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Appius Claudius Ap.f. Crassus Inregillensis S...</td>\n",
       "      <td>Senatoris Romanus Appius Claudius A.f. Crassus...</td>\n",
       "      <td>Appius Claudius Ap.f. Quod igitur, quod in eo, ae</td>\n",
       "      <td>la.la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>%; left: %; height: 0; width: 0; margin: 0; p...</td>\n",
       "      <td>Calleva Atrebatum, civitas Romana in Brittania...</td>\n",
       "      <td>%; left: margin: 0; width: 1em; box-shadow: 8p...</td>\n",
       "      <td>la.la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Valie Export (natus die 17 Maii 1940 Lentiae ...</td>\n",
       "      <td>Anno 1967, laborantem Hungaricum Lentia opus c...</td>\n",
       "      <td>Valie Export (natus die 17 Maii 1940 Lentiae n...</td>\n",
       "      <td>la.la</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prompt  \\\n",
       "0     Hesiodus (floruit saeculo 8 vel 7 a.C.n.) fui...   \n",
       "1     Ars oecologica, vel ars circumiectorum, est n...   \n",
       "2     Coronatio regis Philippi II (1179) Sacrum siv...   \n",
       "3     Metatypia est talis mutatio morphosyntactica ...   \n",
       "4     Crux Sancti Augustini est monumentum lapideum...   \n",
       "..                                                 ...   \n",
       "245   Philosophia neoscholastica, vulgo thomismus n...   \n",
       "246   Lingua bavarica est lingua cum multis varieta...   \n",
       "247   Appius Claudius Ap.f. Crassus Inregillensis S...   \n",
       "248   %; left: %; height: 0; width: 0; margin: 0; p...   \n",
       "249   Valie Export (natus die 17 Maii 1940 Lentiae ...   \n",
       "\n",
       "                                                answer  \\\n",
       "0    Hesiodus, circa 4-11 a.C.n. natus, est poeta G...   \n",
       "1    Verbum \"oecologicum Ars,\" sive \"circumiectum\" ...   \n",
       "2    In anno 1179 rex Philippus II Francorum sacrae...   \n",
       "3    Metatypia, a Malcolm D. Ross anno 1999 coincta...   \n",
       "4    Saint Augustine Church, monumentum lapideum, i...   \n",
       "..                                                 ...   \n",
       "245  Ratio Neo-Scholatica, etiam vocabulo Neo-Schol...   \n",
       "246  Anglice lingua meridiana, cum dialecticiis mul...   \n",
       "247  Senatoris Romanus Appius Claudius A.f. Crassus...   \n",
       "248  Calleva Atrebatum, civitas Romana in Brittania...   \n",
       "249  Anno 1967, laborantem Hungaricum Lentia opus c...   \n",
       "\n",
       "                                        generated_text prefix  \n",
       "0    Hesiodus (floruit saeculo 8 vel 7 a.C.n. Et ig...  la.la  \n",
       "1    Ars oecologica, vel ars circumiectorum, est no...  la.la  \n",
       "2    Coronatio regis Philippi II (1179) Benedictus ...  la.la  \n",
       "3    Metatypia est talis mutatio morphosyntactica e...  la.la  \n",
       "4    Crux Sancti Augustini est monumentum lapideum ...  la.la  \n",
       "..                                                 ...    ...  \n",
       "245  Philosophia neoscholastica, vulgo thomismus ne...  la.la  \n",
       "246  Lingua bavarica est lingua cum multis varietat...  la.la  \n",
       "247  Appius Claudius Ap.f. Quod igitur, quod in eo, ae  la.la  \n",
       "248  %; left: margin: 0; width: 1em; box-shadow: 8p...  la.la  \n",
       "249  Valie Export (natus die 17 Maii 1940 Lentiae n...  la.la  \n",
       "\n",
       "[250 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Baseline not Found for bert-base-multilingual-cased on la at /Data/AxelDlv/condaenvs/LatinSummarizer/lib/python3.11/site-packages/bert_score/rescale_baseline/la/bert-base-multilingual-cased.tsv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ROUGE-1': 0.11479018707862715,\n",
       " 'ROUGE-2': 0.07453752259820665,\n",
       " 'ROUGE-L': 0.10303360427095162,\n",
       " 'BERTScore-F1': 0.6328240036964417}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = calculate_rouge_and_bertscore(\n",
    "    test_data_, tokenizer, model, max_examples_to_test=300, \n",
    "    column_prompt=\"prompt\", column_target=\"answer\", column_prefix=\"prefix\", \n",
    "    max_input_len=1000, max_output_len=512\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rate the summaries with mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /users/eleves-b/2022/axel.delaval/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /users/eleves-b/2022/axel.delaval/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from utils.extractive_summary import extractive_summary, pretty_print_summary\n",
    "from utils.grade_extractive_summary import evaluate_summary, load_model, convert_output_to_grade\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH=\"/Data/AxelDlv/mt5-small-en-la-translation/Mistral-7B-Instruct-v0.3/\"\n",
    "tokenizer_name=\"tokenizer.model.v3\"\n",
    "path_test_data = \"/Data/AxelDlv/LatinSummarizer/test_data_generated_finalmodel_beforefinetuning.csv\"\n",
    "DOWNLOAD_MODEL=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load_model(MODEL_PATH=MODEL_PATH, tokenizer_name=tokenizer_name, DOWNLOAD_MODEL=DOWNLOAD_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "      <th>generated_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hesiodus (floruit saeculo 8 vel 7 a.C.n.) fui...</td>\n",
       "      <td>Hesiodus, circa 4-11 a.C.n. natus, est poeta G...</td>\n",
       "      <td>Hesiodus (floruit saeculo 8 vel 7 a.C.n. Et ig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ars oecologica, vel ars circumiectorum, est n...</td>\n",
       "      <td>Verbum \"oecologicum Ars,\" sive \"circumiectum\" ...</td>\n",
       "      <td>Ars oecologica, vel ars circumiectorum, est no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronatio regis Philippi II (1179) Sacrum siv...</td>\n",
       "      <td>In anno 1179 rex Philippus II Francorum sacrae...</td>\n",
       "      <td>Coronatio regis Philippi II (1179) Benedictus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Metatypia est talis mutatio morphosyntactica ...</td>\n",
       "      <td>Metatypia, a Malcolm D. Ross anno 1999 coincta...</td>\n",
       "      <td>Metatypia est talis mutatio morphosyntactica e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Crux Sancti Augustini est monumentum lapideum...</td>\n",
       "      <td>Saint Augustine Church, monumentum lapideum, i...</td>\n",
       "      <td>Crux Sancti Augustini est monumentum lapideum ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Philosophia neoscholastica, vulgo thomismus n...</td>\n",
       "      <td>Ratio Neo-Scholatica, etiam vocabulo Neo-Schol...</td>\n",
       "      <td>Philosophia neoscholastica, vulgo thomismus ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Lingua bavarica est lingua cum multis varieta...</td>\n",
       "      <td>Anglice lingua meridiana, cum dialecticiis mul...</td>\n",
       "      <td>Lingua bavarica est lingua cum multis varietat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Appius Claudius Ap.f. Crassus Inregillensis S...</td>\n",
       "      <td>Senatoris Romanus Appius Claudius A.f. Crassus...</td>\n",
       "      <td>Appius Claudius Ap.f. Quod igitur, quod in eo, ae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>%; left: %; height: 0; width: 0; margin: 0; p...</td>\n",
       "      <td>Calleva Atrebatum, civitas Romana in Brittania...</td>\n",
       "      <td>%; left: margin: 0; width: 1em; box-shadow: 8p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Valie Export (natus die 17 Maii 1940 Lentiae ...</td>\n",
       "      <td>Anno 1967, laborantem Hungaricum Lentia opus c...</td>\n",
       "      <td>Valie Export (natus die 17 Maii 1940 Lentiae n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prompt  \\\n",
       "0     Hesiodus (floruit saeculo 8 vel 7 a.C.n.) fui...   \n",
       "1     Ars oecologica, vel ars circumiectorum, est n...   \n",
       "2     Coronatio regis Philippi II (1179) Sacrum siv...   \n",
       "3     Metatypia est talis mutatio morphosyntactica ...   \n",
       "4     Crux Sancti Augustini est monumentum lapideum...   \n",
       "..                                                 ...   \n",
       "245   Philosophia neoscholastica, vulgo thomismus n...   \n",
       "246   Lingua bavarica est lingua cum multis varieta...   \n",
       "247   Appius Claudius Ap.f. Crassus Inregillensis S...   \n",
       "248   %; left: %; height: 0; width: 0; margin: 0; p...   \n",
       "249   Valie Export (natus die 17 Maii 1940 Lentiae ...   \n",
       "\n",
       "                                                answer  \\\n",
       "0    Hesiodus, circa 4-11 a.C.n. natus, est poeta G...   \n",
       "1    Verbum \"oecologicum Ars,\" sive \"circumiectum\" ...   \n",
       "2    In anno 1179 rex Philippus II Francorum sacrae...   \n",
       "3    Metatypia, a Malcolm D. Ross anno 1999 coincta...   \n",
       "4    Saint Augustine Church, monumentum lapideum, i...   \n",
       "..                                                 ...   \n",
       "245  Ratio Neo-Scholatica, etiam vocabulo Neo-Schol...   \n",
       "246  Anglice lingua meridiana, cum dialecticiis mul...   \n",
       "247  Senatoris Romanus Appius Claudius A.f. Crassus...   \n",
       "248  Calleva Atrebatum, civitas Romana in Brittania...   \n",
       "249  Anno 1967, laborantem Hungaricum Lentia opus c...   \n",
       "\n",
       "                                        generated_text  \n",
       "0    Hesiodus (floruit saeculo 8 vel 7 a.C.n. Et ig...  \n",
       "1    Ars oecologica, vel ars circumiectorum, est no...  \n",
       "2    Coronatio regis Philippi II (1179) Benedictus ...  \n",
       "3    Metatypia est talis mutatio morphosyntactica e...  \n",
       "4    Crux Sancti Augustini est monumentum lapideum ...  \n",
       "..                                                 ...  \n",
       "245  Philosophia neoscholastica, vulgo thomismus ne...  \n",
       "246  Lingua bavarica est lingua cum multis varietat...  \n",
       "247  Appius Claudius Ap.f. Quod igitur, quod in eo, ae  \n",
       "248  %; left: margin: 0; width: 1em; box-shadow: 8p...  \n",
       "249  Valie Export (natus die 17 Maii 1940 Lentiae n...  \n",
       "\n",
       "[250 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_ = pd.read_csv(path_test_data)\n",
    "test_data_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [09:44<00:00,  2.34s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "      <th>generated_text</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hesiodus (floruit saeculo 8 vel 7 a.C.n.) fui...</td>\n",
       "      <td>Hesiodus, circa 4-11 a.C.n. natus, est poeta G...</td>\n",
       "      <td>Hesiodus (floruit saeculo 8 vel 7 a.C.n. Et ig...</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ars oecologica, vel ars circumiectorum, est n...</td>\n",
       "      <td>Verbum \"oecologicum Ars,\" sive \"circumiectum\" ...</td>\n",
       "      <td>Ars oecologica, vel ars circumiectorum, est no...</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronatio regis Philippi II (1179) Sacrum siv...</td>\n",
       "      <td>In anno 1179 rex Philippus II Francorum sacrae...</td>\n",
       "      <td>Coronatio regis Philippi II (1179) Benedictus ...</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Metatypia est talis mutatio morphosyntactica ...</td>\n",
       "      <td>Metatypia, a Malcolm D. Ross anno 1999 coincta...</td>\n",
       "      <td>Metatypia est talis mutatio morphosyntactica e...</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Crux Sancti Augustini est monumentum lapideum...</td>\n",
       "      <td>Saint Augustine Church, monumentum lapideum, i...</td>\n",
       "      <td>Crux Sancti Augustini est monumentum lapideum ...</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Philosophia neoscholastica, vulgo thomismus n...</td>\n",
       "      <td>Ratio Neo-Scholatica, etiam vocabulo Neo-Schol...</td>\n",
       "      <td>Philosophia neoscholastica, vulgo thomismus ne...</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Lingua bavarica est lingua cum multis varieta...</td>\n",
       "      <td>Anglice lingua meridiana, cum dialecticiis mul...</td>\n",
       "      <td>Lingua bavarica est lingua cum multis varietat...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Appius Claudius Ap.f. Crassus Inregillensis S...</td>\n",
       "      <td>Senatoris Romanus Appius Claudius A.f. Crassus...</td>\n",
       "      <td>Appius Claudius Ap.f. Quod igitur, quod in eo, ae</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>%; left: %; height: 0; width: 0; margin: 0; p...</td>\n",
       "      <td>Calleva Atrebatum, civitas Romana in Brittania...</td>\n",
       "      <td>%; left: margin: 0; width: 1em; box-shadow: 8p...</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Valie Export (natus die 17 Maii 1940 Lentiae ...</td>\n",
       "      <td>Anno 1967, laborantem Hungaricum Lentia opus c...</td>\n",
       "      <td>Valie Export (natus die 17 Maii 1940 Lentiae n...</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prompt  \\\n",
       "0     Hesiodus (floruit saeculo 8 vel 7 a.C.n.) fui...   \n",
       "1     Ars oecologica, vel ars circumiectorum, est n...   \n",
       "2     Coronatio regis Philippi II (1179) Sacrum siv...   \n",
       "3     Metatypia est talis mutatio morphosyntactica ...   \n",
       "4     Crux Sancti Augustini est monumentum lapideum...   \n",
       "..                                                 ...   \n",
       "245   Philosophia neoscholastica, vulgo thomismus n...   \n",
       "246   Lingua bavarica est lingua cum multis varieta...   \n",
       "247   Appius Claudius Ap.f. Crassus Inregillensis S...   \n",
       "248   %; left: %; height: 0; width: 0; margin: 0; p...   \n",
       "249   Valie Export (natus die 17 Maii 1940 Lentiae ...   \n",
       "\n",
       "                                                answer  \\\n",
       "0    Hesiodus, circa 4-11 a.C.n. natus, est poeta G...   \n",
       "1    Verbum \"oecologicum Ars,\" sive \"circumiectum\" ...   \n",
       "2    In anno 1179 rex Philippus II Francorum sacrae...   \n",
       "3    Metatypia, a Malcolm D. Ross anno 1999 coincta...   \n",
       "4    Saint Augustine Church, monumentum lapideum, i...   \n",
       "..                                                 ...   \n",
       "245  Ratio Neo-Scholatica, etiam vocabulo Neo-Schol...   \n",
       "246  Anglice lingua meridiana, cum dialecticiis mul...   \n",
       "247  Senatoris Romanus Appius Claudius A.f. Crassus...   \n",
       "248  Calleva Atrebatum, civitas Romana in Brittania...   \n",
       "249  Anno 1967, laborantem Hungaricum Lentia opus c...   \n",
       "\n",
       "                                        generated_text  grade  \n",
       "0    Hesiodus (floruit saeculo 8 vel 7 a.C.n. Et ig...   19.0  \n",
       "1    Ars oecologica, vel ars circumiectorum, est no...   49.0  \n",
       "2    Coronatio regis Philippi II (1179) Benedictus ...   19.0  \n",
       "3    Metatypia est talis mutatio morphosyntactica e...   50.0  \n",
       "4    Crux Sancti Augustini est monumentum lapideum ...   30.0  \n",
       "..                                                 ...    ...  \n",
       "245  Philosophia neoscholastica, vulgo thomismus ne...   29.0  \n",
       "246  Lingua bavarica est lingua cum multis varietat...    1.0  \n",
       "247  Appius Claudius Ap.f. Quod igitur, quod in eo, ae    0.0  \n",
       "248  %; left: margin: 0; width: 1em; box-shadow: 8p...   20.0  \n",
       "249  Valie Export (natus die 17 Maii 1940 Lentiae n...   19.0  \n",
       "\n",
       "[250 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_['grade'] = test_data_.progress_apply(lambda x: evaluate_summary(x['prompt'], x['generated_text'], model, tokenizer, n_tokens=10), axis=1)\n",
    "test_data_['grade'] = test_data_['grade'].apply(lambda x: convert_output_to_grade(x))\n",
    "test_data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics on the grades:\n",
      "Mean grade: 27.384\n",
      "Median grade: 29.0\n",
      "Standard deviation: 14.26669894527745\n",
      "Minimum grade: 0.0\n",
      "Maximum grade: 80.0\n"
     ]
    }
   ],
   "source": [
    "# Plot an histogram of the grades\n",
    "GRADES = test_data_['grade'].value_counts().sort_index()\n",
    "plt.bar(GRADES.index, GRADES.values)\n",
    "plt.xlabel('Grade')\n",
    "plt.ylabel('Number of summaries')\n",
    "plt.title('Distribution of grades')\n",
    "plt.show()\n",
    "\n",
    "# Print statistics on the grades\n",
    "print('Statistics on the grades:')\n",
    "print('Mean grade:', test_data_['grade'].mean())\n",
    "print('Median grade:', test_data_['grade'].median())\n",
    "print('Standard deviation:', test_data_['grade'].std())\n",
    "print('Minimum grade:', test_data_['grade'].min())\n",
    "print('Maximum grade:', test_data_['grade'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "test_data_.to_csv(\"/Data/AxelDlv/LatinSummarizer/test_data_generated_finalmodel_beforefinetuning_withgrades.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
